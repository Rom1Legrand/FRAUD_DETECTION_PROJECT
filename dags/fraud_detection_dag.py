from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from datetime import datetime, timedelta
from utils.common import *
import requests
import joblib
import importlib.util
import json
import os
from sqlalchemy import create_engine, text, Boolean
from sqlalchemy.exc import SQLAlchemyError

default_args = {
    'owner': 'fraud_team',
    'depends_on_past': False,
    'email_on_failure': True,
    'retries': 1,
    'retry_delay': timedelta(minutes=1),
}

def load_dependencies(**context):
    """Charge le mod√®le et l'ETL depuis S3"""
    try:
        logger.info("Chargement des d√©pendances depuis S3...")
        s3_client = get_s3_client()
        
        # Cr√©ation du dossier temporaire
        tmp_dir = '/tmp/fraud_detection'
        os.makedirs(tmp_dir, exist_ok=True)
        
        # Configuration des chemins S3 avec le prefix
        s3_paths = {
            'model': f"{S3_PREFIX}/models/random_forest_model.pkl",
            'etl': f"{S3_PREFIX}/etl/etl.py"
        }
        
        # Chargement du mod√®le
        model_path = f"{tmp_dir}/model.pkl"
        s3_client.download_file(
            S3_BUCKET,
            s3_paths['model'],
            model_path
        )
        logger.info("Mod√®le charg√© avec succ√®s")
        
        # Chargement de l'ETL
        etl_path = f"{tmp_dir}/etl.py"
        s3_client.download_file(
            S3_BUCKET,
            s3_paths['etl'],
            etl_path
        )
        logger.info("ETL charg√© avec succ√®s")
        
        # Stockage des chemins dans le contexte
        context['task_instance'].xcom_push(key='model_path', value=model_path)
        context['task_instance'].xcom_push(key='etl_path', value=etl_path)
        
        return True
        
    except Exception as e:
        logger.error(f"Erreur lors du chargement des d√©pendances: {str(e)}")
        raise

def fetch_api(**context):
    try:
        response = requests.get(API_URL)
        response.raise_for_status()
        transactions = response.json()
        logger.info("Transaction re√ßue avec succ√®s")
        context['ti'].xcom_push(key='transactions', value=transactions)

    except Exception as e:
        logger.error(f"Erreur de connexion √† l'API: {str(e)}")
        raise

def process_transaction(**context):
    try:
        # R√©cup√©ration des donn√©es avec une meilleure gestion d'erreur
        task_instance = context['task_instance']
        raw_transactions = task_instance.xcom_pull(task_ids='fetch_api', key='transactions')
        
        logger.info(f"Donn√©es r√©cup√©r√©es depuis XCom: {raw_transactions}")

        if not raw_transactions:
            logger.warning("Pas de donn√©es √† traiter")
            return 'skip_processing'
        
        # Parsing JSON
        transactions = json.loads(raw_transactions)
        logger.info("Donn√©es JSON pars√©es avec succ√®s")
            
        # Cr√©ation du DataFrame
        df = pd.DataFrame(transactions['data'], columns=transactions['columns'])
        logger.info(f"DataFrame cr√©√© avec {len(df)} lignes")
        
        # Renommage de la colonne current_time en trans_date_trans_time
        df = df.rename(columns={'current_time': 'trans_date_trans_time'})
        logger.info("Colonnes renomm√©es avec succ√®s")
        logger.info(f"Colonnes disponibles: {df.columns.tolist()}")

        # Conversion en timestamp Unix (en secondes)
        df['unix_time'] = df['trans_date_trans_time'].astype('int64') // 10**9  # Conversion en secondes
        logger.info("Conversion de trans_date_trans_time en unix_time r√©ussie")
        
        # Import de l'ETL
        etl_path = context['ti'].xcom_pull(task_ids='load_dependencies', key='etl_path')
        spec = importlib.util.spec_from_file_location("etl", etl_path)
        etl = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(etl)
        
        # Transformation des donn√©es
        logger.info("Transformation des donn√©es...")
        df_transformed = etl.transform_data(df)
        
        # Chargement et pr√©diction avec le mod√®le
        model_path = context['ti'].xcom_pull(task_ids='load_dependencies', key='model_path')
        model = joblib.load(model_path)
        
        # Pr√©diction
        prediction = model.predict(df_transformed)[0]
        probability = model.predict_proba(df_transformed)[:, 1][0]

        # Ajout du logging pour la pr√©diction et la probabilit√©
        logger.info(f"Prediction de fraude: {'FRAUDE' if prediction == 1 else 'NORMAL'}, Probabilit√©: {probability:.2%}")
        
        # Stockage des r√©sultats
        context['ti'].xcom_push(key='is_fraud', value=bool(prediction))
        context['ti'].xcom_push(key='fraud_probability', value=float(probability))

        logger.info(f"Pr√©diction: {'FRAUDE' if prediction == 1 else 'NORMAL'} (Probabilit√©: {probability:.2%})")
        
        # version √† remettre quand email sera verif : return 'send_fraud_alert' if prediction == 1 else 'store_normal'
        return 'notify_fraud' if prediction == 1 else 'notify_normal'

    except Exception as e:
        logger.error(f"Erreur lors du traitement: {str(e)}")
        logger.error(f"Type des transactions: {type(raw_transactions)}")
        logger.error(f"Contenu des transactions: {str(raw_transactions)[:200]}...")
        return 'skip_processing' 

# quand je serai sur que l'email s'envoie bien le remettrai ci-dessous et surpprimerai l'envoie d'email globaux
'''def alert_fraud(**context):
    try:
        # R√©cup√©ration des donn√©es
        transaction = context['task_instance'].xcom_pull(task_ids='fetch_api', key='transactions')
        probability = context['task_instance'].xcom_pull(key='fraud_probability')
        
        logger.info(f"Donn√©es de transaction r√©cup√©r√©es: {transaction}")
        logger.info(f"Probabilit√© de fraude: {probability}")
        
        # V√©rification des donn√©es
        if transaction is None:
            logger.error("Aucune donn√©e de transaction trouv√©e dans XCom.")
            return 'store_fraud'

        if probability is None:
            logger.error("Aucune probabilit√© de fraude trouv√©e dans XCom.")
            return 'store_fraud'
            
        # Parser le JSON si n√©cessaire
        if isinstance(transaction, str):
            transaction = json.loads(transaction)
            
        # Convertir en DataFrame pour faciliter l'acc√®s aux donn√©es
        df = pd.DataFrame(transaction['data'], columns=transaction['columns']).iloc[0]
        
        # Formatage du montant avec 2 d√©cimales
        amount = "{:.2f}".format(float(df['amt']))
        
        # Formatage de la date
        transaction_date = pd.to_datetime(df['current_time'], unit='ms').strftime('%Y-%m-%d %H:%M:%S')
        
        body = f"""
        üö® ALERTE: Transaction frauduleuse d√©tect√©e!
        
        Probabilit√© de fraude: {probability:.2%}
        
        D√©tails de la transaction:
        --------------------------
        ID Transaction: {df['trans_num']}
        Montant: {amount}‚Ç¨
        Date/Heure: {transaction_date}
        
        Informations sur le marchand:
        ----------------------------
        Nom: {df['merchant']}
        Ville: {df['city']}
        √âtat: {df['state']}
        
        Informations sur le client:
        --------------------------
        Nom: {df['first']} {df['last']}
        Ville: {df['city']}
        
        Cette alerte a √©t√© g√©n√©r√©e automatiquement par le syst√®me de d√©tection de fraude.
        """
        
        logger.info("Tentative d'envoi d'email d'alerte...")
        logger.info(f"Contenu de l'email:\n{body}")
        
        # Envoi de l'email avec gestion des destinataires
        recipients = os.environ.get('ALERT_EMAIL', 'default@email.com').split(',')
        send_email(
            subject="üö® ALERTE FRAUDE", 
            body=body,
            to=recipients
        )
        
        logger.info("Email d'alerte envoy√© avec succ√®s")
        return 'store_fraud'
        
    except Exception as e:
        logger.error(f"Erreur lors de l'envoi de l'alerte: {str(e)}")
        return 'store_fraud'  # On continue vers le stockage m√™me en cas d'erreur d'envoi'''

def send_transaction_email(**context):
    try:
        # R√©cup√©ration des donn√©es
        transaction = context['task_instance'].xcom_pull(task_ids='fetch_api', key='transactions')
        probability = context['task_instance'].xcom_pull(key='fraud_probability')
        is_fraud = context['task_instance'].xcom_pull(key='is_fraud', default=False)
        
        logger.info(f"Donn√©es de transaction r√©cup√©r√©es: {transaction}")
        logger.info(f"Probabilit√© de fraude: {probability}")
        logger.info(f"Est une fraude: {is_fraud}")
        
        # V√©rification des donn√©es
        if transaction is None:
            logger.error("Aucune donn√©e de transaction trouv√©e dans XCom.")
            return 'store_normal' if not is_fraud else 'store_fraud'

        if probability is None:
            logger.error("Aucune probabilit√© de fraude trouv√©e dans XCom.")
            return 'store_normal' if not is_fraud else 'store_fraud'
            
        # Parser le JSON si n√©cessaire
        if isinstance(transaction, str):
            transaction = json.loads(transaction)
            
        # Convertir en DataFrame pour faciliter l'acc√®s aux donn√©es
        df = pd.DataFrame(transaction['data'], columns=transaction['columns']).iloc[0]
        
        # Formatage du montant avec 2 d√©cimales
        amount = "{:.2f}".format(float(df['amt']))
        
        # Formatage de la date
        transaction_date = pd.to_datetime(df['current_time'], unit='ms').strftime('%Y-%m-%d %H:%M:%S')

        # Construction du sujet et du contenu en fonction du type de transaction
        if is_fraud:
            subject = "üö® ALERTE: Transaction frauduleuse d√©tect√©e!"
            status_color = "Rouge"
            status_text = "FRAUDULEUSE"
        else:
            subject = "‚úÖ INFO: Transaction normale d√©tect√©e"
            status_color = "Vert"
            status_text = "NORMALE"
        
        body = f"""
        {'üö®' if is_fraud else '‚úÖ'} Transaction {status_text} d√©tect√©e!
        
        Statut: {status_color}
        Probabilit√© de fraude: {probability:.2%}
        
        D√©tails de la transaction:
        --------------------------
        ID Transaction: {df['trans_num']}
        Montant: {amount}‚Ç¨
        Date/Heure: {transaction_date}
        
        Informations sur le marchand:
        ----------------------------
        Nom: {df['merchant']}
        Ville: {df['city']}
        √âtat: {df['state']}
        
        Informations sur le client:
        --------------------------
        Nom: {df['first']} {df['last']}
        Ville: {df['city']}
        
        Cette notification a √©t√© g√©n√©r√©e automatiquement par le syst√®me de d√©tection de fraude.
        """
        
        logger.info(f"Tentative d'envoi d'email {status_text.lower()}...")
        logger.info(f"Contenu de l'email:\n{body}")
        
        # Utilisation de la fonction send_email de common.py
        success = send_email(
            subject=subject, 
            body=body
            # On n'envoie pas to_email pour utiliser l'email par d√©faut
        )
        
        if success:
            logger.info("Email envoy√© avec succ√®s")
        else:
            logger.error("√âchec de l'envoi de l'email")
            
        return 'store_normal' if not is_fraud else 'store_fraud'
        
    except Exception as e:
        logger.error(f"Erreur lors de l'envoi de l'email: {str(e)}")
        return 'store_normal' if not is_fraud else 'store_fraud'

def store_transaction(**context):
    try:
        # Test de connexion √† Neon
        db_url = os.environ.get('NEON_DATABASE_URL')
        if not db_url:
            logger.error("NEON_DATABASE_URL n'est pas d√©finie")
            raise ValueError("NEON_DATABASE_URL manquante")
            
        logger.info("Tentative de connexion √† Neon...")
        engine = create_engine(db_url)
        
        # Test simple de connexion
        with engine.connect() as connection:
            result = connection.execute(text("SELECT 1"))
            logger.info("Connexion √† Neon r√©ussie!")
        
        # R√©cup√©ration et parsing des donn√©es
        raw_transactions = context['task_instance'].xcom_pull(
            task_ids='fetch_api', 
            key='transactions'
        )
        logger.info(f"Donn√©es re√ßues pour stockage: {raw_transactions}")
        
        if not raw_transactions:
            logger.error("Aucune donn√©e de transaction trouv√©e dans XCom.")
            return
            
        # Parser le JSON si c'est une cha√Æne
        if isinstance(raw_transactions, str):
            raw_transactions = json.loads(raw_transactions)
            logger.info("JSON pars√© avec succ√®s")
        
        # Cr√©ation du DataFrame
        df = pd.DataFrame(raw_transactions['data'], columns=raw_transactions['columns'])
        logger.info(f"DataFrame cr√©√© avec {len(df)} lignes")

        # Renommer la colonne current_time en trans_date_trans_time
        if 'current_time' in df.columns:
            df = df.rename(columns={'current_time': 'trans_date_trans_time'})
            logger.info("Colonne current_time renomm√©e en trans_date_trans_time")
        
        # Convertir le timestamp en datetime
        df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], unit='ms')
        logger.info("Conversion du timestamp r√©ussie")

        # Convertir is_fraud en boolean
        df['is_fraud'] = df['is_fraud'].astype(bool)
        logger.info("Conversion de is_fraud en boolean r√©ussie")

        # Log des colonnes et types
        logger.info(f"Colonnes finales avant stockage: {df.columns.tolist()}")
        logger.info(f"Types des donn√©es: \n{df.dtypes}")

        # R√©cup√©ration de l'indicateur de fraude
        is_fraud = context['task_instance'].xcom_pull(key='is_fraud', default=False)
        logger.info(f"Indicateur de fraude r√©cup√©r√©: {is_fraud}")

        # D√©termination de la table cible
        table = 'fraud_transactions' if is_fraud else 'normal_transactions'
        logger.info(f"Stockage dans la table: {table}")
        
        # Stockage des donn√©es avec dtype sp√©cifi√© pour is_fraud
        dtype = {'is_fraud': Boolean}
        df.to_sql(table, engine, if_exists='append', index=False, dtype=dtype)
        logger.info(f"Donn√©es stock√©es avec succ√®s dans la table {table}")

    except SQLAlchemyError as e:
        logger.error(f"Erreur SQLAlchemy: {str(e)}")
        if 'df' in locals():
            logger.error(f"Colonnes du DataFrame: {df.columns.tolist()}")
            logger.error(f"Types des donn√©es: \n{df.dtypes}")
        raise
    except Exception as e:
        logger.error(f"Erreur inattendue: {str(e)}")
        logger.error(f"Type des donn√©es re√ßues: {type(raw_transactions)}")
        raise

def store_normal(**context):
    """Wrapper pour stocker les transactions normales"""
    context['task_instance'].xcom_push(key='is_fraud', value=False)
    return store_transaction(**context)

def store_fraud(**context):
    """Wrapper pour stocker les transactions frauduleuses"""
    context['task_instance'].xcom_push(key='is_fraud', value=True)
    return store_transaction(**context)

with DAG(
    'fraud_detection',
    default_args=default_args,
    description='D√©tection de fraude en temps r√©el',
    schedule_interval='* * * * *',
    start_date=datetime(2024, 1, 1),
    catchup=False
) as dag:
    
    # Chargement des d√©pendances
    load_deps = PythonOperator(
        task_id='load_dependencies',
        python_callable=load_dependencies,
    )

    # R√©cup√©ration des donn√©es de l'API
    fetch_api = PythonOperator(
        task_id='fetch_api',
        python_callable=fetch_api,
        do_xcom_push=True,
    )

    # Traitement et pr√©diction
    process = BranchPythonOperator(
        task_id='process_transaction',
        python_callable=process_transaction,
    )

    # Email et stockage pour transactions normales
    notify_normal = PythonOperator(
        task_id='notify_normal',
        python_callable=send_transaction_email,
        provide_context=True
    )

    store_normal = PythonOperator(
        task_id='store_normal',
        python_callable=store_transaction,
        provide_context=True
    )

    # Email et stockage pour transactions frauduleuses
    notify_fraud = PythonOperator(
        task_id='notify_fraud',
        python_callable=send_transaction_email,
        provide_context=True
    )

    store_fraud = PythonOperator(
        task_id='store_fraud',
        python_callable=store_transaction,
        provide_context=True
    )

    skip = PythonOperator(
        task_id='skip_processing',
        python_callable=lambda: logger.info("Pas de donn√©es")
    )

    # D√©finition des d√©pendances
    load_deps >> fetch_api >> process >> [notify_normal, notify_fraud, skip]
    notify_normal >> store_normal
    notify_fraud >> store_fraud


    # quand je serais sur que le code fonctionne je supprimerai au dessus et je mettrai le code ci dessous
    '''load_deps = PythonOperator(
        task_id='load_dependencies',
        python_callable=load_dependencies,
    )

    fetch_api = PythonOperator(
        task_id='fetch_api',
        python_callable=fetch_api,
        do_xcom_push=True,  # Assurez-vous que XCom est activ√©
    )

    process = BranchPythonOperator(
        task_id='process_transaction',
        python_callable=process_transaction,
        provide_context=True,
        trigger_rule='all_success',  # S'assure que toutes les t√¢ches pr√©c√©dentes sont r√©ussies
    )

    store_normal = PythonOperator(
    task_id='store_normal',
    python_callable=store_normal,
    provide_context=True
    )   

    send_alert = PythonOperator(
        task_id='send_fraud_alert',
        python_callable=alert_fraud,
        provide_context=True
    )

    store_fraud = PythonOperator(
    task_id='store_fraud',
    python_callable=store_fraud,
    provide_context=True
    )

    skip = PythonOperator(
        task_id='skip_processing',
        python_callable=lambda: logger.info("Pas de donn√©es")
    )

    load_deps >> fetch_api >> process >> [store_normal, send_alert, skip]
    send_alert >> store_fraud'''